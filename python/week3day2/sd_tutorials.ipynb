{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface Transformers & Stable Diffusion\n",
    "> 郑问迪\n",
    "> zhengwd23@mails.tsinghua.edu.cn\n",
    "\n",
    "- Huggingface Transformers: https://huggingface.co/\n",
    "\n",
    "    Huggingface🤗 (HF) 是一个提供数据科学与机器学习相关开源模型及数据的平台。\n",
    "    \n",
    "    通过HF提供的`transformers`库，你可以仅使用若干行代码非常便捷地调用开源的模型实现推理及训练等自定义需求。\n",
    "- Stable Diffusion: https://github.com/CompVis/stable-diffusion\n",
    "\n",
    "    文本到图像扩散生成模型（Diffusion Models for Text-to-Image）中具有代表性的开源工作。\n",
    "    \n",
    "    Stable Diffusion (SD) 是目前文到图生成社区使用的主流基础模型。\n",
    "    \n",
    "    和官方仓库相比，[webui](https://github.com/AUTOMATIC1111/stable-diffusion-webui) 这个由民间大佬在模型基础上开发的集成仓库似乎更受大家欢迎）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huggingface Transformers\n",
    "\n",
    "> 更多可参照HF官方tutorial：https://huggingface.co/docs/transformers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于 torch / tensorflow\n",
    "# 本文档基于torch演示\n",
    "# 安装\n",
    "%pip install transformers datasets\n",
    "%pip install accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`transformers.pipeline`: 使用模型进行推理的API\n",
    "\n",
    "部分任务的用法示例如下：\n",
    "| 任务 | 用法 |\n",
    "| :-- | :-- |\n",
    "| 文本分类（Text classification）      | pipeline(task=“sentiment-analysis”)   |\n",
    "| 文本生成（Text generation）          | pipeline(task=“text-generation”)      |\n",
    "| 图像分类（Image classification）     | pipeline(task=“image-classification”) |\n",
    "| 目标检测（Image classification）     | pipeline(task=“image-segmentation”)   |\n",
    "| 视觉问答（Visual question answering）| pipeline(task=“vqa”)                  |\n",
    "| 图像标注（Image captioning）         | pipeline(task=“image-to-text”)        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以情感分类为例\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "results = classifier([\n",
    "    \"We are very happy to introduce python and transformers to you.\",\n",
    "    \"So sad you didn't attend the class.\"\n",
    "])\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在pipeline中使用非默认的另外指定的module（比如model和tokenizer）\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "results = classifier([\n",
    "    \"We are very happy to introduce python and transformers to you.\",\n",
    "    \"So sad you didn't attend the class.\"\n",
    "])\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`transformers.Trainer`: 训练模型的API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仍以训练情感分类模型为例\n",
    "\n",
    "# 载入预训练模型\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入数据集\n",
    "# 载入使用的tokenizer并定义预处理函数\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "    return tokenizer(dataset[\"text\"])\n",
    "dataset = dataset.map(tokenize_dataset, batched=True) # apply tokenize function to the dataset\n",
    "\n",
    "# 从数据集获取数据并为训练提供批次（batch）的数据\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置训练参数\n",
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"path/to/save/folder/\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行trainer的初始化\n",
    "from transformers import Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")  # doctest: +SKIP\n",
    "\n",
    "# 使用trainer进行训练\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Diffusion\n",
    "\n",
    "> 主要使用diffuser：huggingface推出的使用diffusion model的库。\n",
    "> https://huggingface.co/docs/diffusers/index\n",
    "> WebUI提供了更加便捷的LoRA接口，也有更丰富的LoRA社区建设。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装依赖库\n",
    "%pip install diffusers\n",
    "%pip install safetensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 文本到图像生成，图像到图像生成，图像补全， etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "from diffusers import StableDiffusionXLPipeline\n",
    "import torch\n",
    "\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
    ")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "# Text-to-image generation: 根据文本生成图像\n",
    "prompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\n",
    "image = pipe(prompt=prompt).images[0]\n",
    "image.save(\"generations/t2i.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inpainting: 图像补全\n",
    "from diffusers import StableDiffusionXLInpaintPipeline\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "img_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\n",
    "mask_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\"\n",
    "\n",
    "init_image = load_image(img_url).convert(\"RGB\")\n",
    "mask_image = load_image(mask_url).convert(\"RGB\")\n",
    "\n",
    "prompt = \"A majestic tiger sitting on a bench\"\n",
    "image = pipe(prompt=prompt, image=init_image, mask_image=mask_image, num_inference_steps=50, strength=0.80).images[0]\n",
    "image.save(\"generations/inpaint.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image-to-image generation: 图像到图像生成\n",
    "from diffusers import StableDiffusionXLImg2ImgPipeline\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "# 使用适配该任务的模型\n",
    "pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-refiner-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "url = \"https://huggingface.co/datasets/patrickvonplaten/images/resolve/main/aa_xl/000000009.png\"\n",
    "\n",
    "init_image = load_image(url).convert(\"RGB\")\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "image = pipe(prompt, image=init_image).images[0]\n",
    "image.save(\"generations/i2i.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加Lora进行风格化生成\n",
    "# https://huggingface.co/spaces/multimodalart/LoraTheExplorer\n",
    "# https://civitai.com\n",
    "from diffusers import StableDiffusionXLPipeline\n",
    "import torch\n",
    "\n",
    "# 加载base model\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
    ")\n",
    "pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lora: Pixel Art XL\n",
    "pipe.load_lora_weights(\"nerijs/pixel-art-xl\", weight_name=\"pixel-art-xl.safetensors\")\n",
    "prompt = \"pixel art...\"\n",
    "lora_scale= 0.9\n",
    "image = pipe(prompt, num_inference_steps=30, guidance_scale=7.5, cross_attention_kwargs={\"scale\": lora_scale}).images[0]\n",
    "image.save(\"image_lora.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio\n",
    "\n",
    "> 简单的demo界面制作库。\n",
    "> 官方文档：https://www.gradio.app/guides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装\n",
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hello world\n",
    "# 作为python脚本时，以`gradio app.py`的形式运行。\n",
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    return f\"Hello world, {name}!\"\n",
    "\n",
    "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 多个不同种类的输入\n",
    "import gradio as gr\n",
    "\n",
    "def greet(name, is_morning, temperature):\n",
    "    salutation = \"Good morning\" if is_morning else \"Good evening\"\n",
    "    greeting = f\"{salutation} {name}. It is {temperature} degrees today\"\n",
    "    celsius = (temperature - 32) * 5 / 9\n",
    "    return greeting, round(celsius, 2)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=[\"text\", \"checkbox\", gr.Slider(0, 100)],\n",
    "    outputs=[\"text\", \"number\"],\n",
    ")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入及输出图像的样例\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "def sepia(input_img):\n",
    "    sepia_filter = np.array([\n",
    "        [0.393, 0.769, 0.189], \n",
    "        [0.349, 0.686, 0.168], \n",
    "        [0.272, 0.534, 0.131]\n",
    "    ])\n",
    "    sepia_img = input_img.dot(sepia_filter.T)\n",
    "    sepia_img /= sepia_img.max()\n",
    "    return sepia_img\n",
    "\n",
    "demo = gr.Interface(sepia, gr.Image(shape=(200, 200)), \"image\")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradio.Blocks() 模块化实现更复杂的gradio配置\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "def flip_text(x):\n",
    "    return x[::-1]\n",
    "\n",
    "def flip_image(x):\n",
    "    return np.fliplr(x)\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"Flip text or image files using this demo.\")\n",
    "    with gr.Tab(\"Flip Text\"):\n",
    "        text_input = gr.Textbox()\n",
    "        text_output = gr.Textbox()\n",
    "        text_button = gr.Button(\"Flip\")\n",
    "    with gr.Tab(\"Flip Image\"):\n",
    "        with gr.Row():\n",
    "            image_input = gr.Image()\n",
    "            image_output = gr.Image()\n",
    "        image_button = gr.Button(\"Flip\")\n",
    "\n",
    "    text_button.click(flip_text, inputs=text_input, outputs=text_output)\n",
    "    image_button.click(flip_image, inputs=image_input, outputs=image_output)\n",
    "    \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End\n",
    "\n",
    "Have fun with channels of Stable Diffusion gradio demos!\n",
    "- https://huggingface.co/spaces/Manjushri/SDXL-1.0\n",
    "- https://stablediffusion.fr/sdxl\n",
    "- https://huggingface.co/spaces/multimodalart/LoraTheExplorer\n",
    "- ...\n",
    "\n",
    "Example prompts:\n",
    "- breathtaking night street of Tokyo, neon lights. award-winning, professional, highly detailed\n",
    "- anime artwork an empty classroom. anime style, key visual, vibrant, studio anime, highly detailed\n",
    "- concept art of dragon flying over town, clouds. digital artwork, illustrative, painterly, matte painting, highly detailed, cinematic composition\n",
    "- ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
